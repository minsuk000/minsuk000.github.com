---
layout:post
title: Bayesian Model Selection and Shrinkage Priors (1)
tags: Bayesian model selection, shrinkage priors
comments: true
---
 There have been a lot of interest in model selection or variable selection methods. Because many data sets have"large p, small n" problem (or high-dimensional problem), it is crucial to reduce the dimension of the data, and the simplest way is to select a small number of  variables that well-fit to the model. I am going to introduce a simple introduction of this framework in Bayesian philosophy.
 
 Let's consider a linear regression model with three predictors as follows:
 
$$ Y_i = \beta_0 + \beta_1 X_{ 1 i } + \beta_2  X_{ 2 i } +\beta_3 X_{3i} + \epsilon_i$$  for $$ i=1,...,n $$.

But suppose that we are not sure that "all" variables are linearly associated with the response (yeah,  linearity is a strong assumption, but for simplicity we just assume it). So we consider several models by selecting some variables as

$$M_1: Y_i = \beta_0 +  \beta_1 X_{ 1 i } + \epsilon_i$$
 
 $$M_2: Y_i = \beta_0 +  \beta_1 X_{ 2 i } + \epsilon_i$$
 
  $$M_3: Y_i = \beta_0 +  \beta_1 X_{ 2 i } +   \beta_1 X_{ 3 i }+\epsilon_i$$,
  
  .... etc. 
  
  Then the number of total possible models is $$2^3$$.
  
  

